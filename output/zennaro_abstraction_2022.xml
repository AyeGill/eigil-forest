<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>312</fr:anchor><fr:taxon>Reference</fr:taxon><fr:addr>zennaro_abstraction_2022</fr:addr><fr:route>zennaro_abstraction_2022.xml</fr:route><fr:source-path>/home/eigil/eigil-forest/trees/refs/zennaro_abstraction_2022.tree</fr:source-path><fr:title>Abstraction between structural causal models: A review of definitions and properties</fr:title><fr:date><fr:year>2022</fr:year><fr:month>7</fr:month><fr:day>18</fr:day></fr:date><fr:authors><fr:author>Fabio Massimo Zennaro</fr:author></fr:authors><fr:meta
name="bibtex">@misc{zennaro_abstraction_2022,
 abstract = {Structural causal models ({SCMs}) are a widespread formalism to deal with causal systems. A recent direction of research has considered the problem of relating formally {SCMs} at different levels of abstraction, by defining maps between {SCMs} and imposing a requirement of interventional consistency. This paper offers a review of the solutions proposed so far, focusing on the formal properties of a map between {SCMs}, and highlighting the different layers (structural, distributional) at which these properties may be enforced. This allows us to distinguish families of abstractions that may or may not be permitted by choosing to guarantee certain properties instead of others. Such an understanding not only allows to distinguish among proposal for causal abstraction with more awareness, but it also allows to tailor the definition of abstraction with respect to the forms of abstraction relevant to specific applications.},
 author = {Zennaro, Fabio Massimo},
 date = {2022-07-18},
 doi = {10.48550/arXiv.2207.08603},
 eprint = {2207.08603 [cs]},
 eprinttype = {arxiv},
 file = {arXiv Fulltext PDF:/home/eigil/Zotero/storage/GBLY4K4U/Zennaro - 2022 - Abstraction between Structural Causal Models A Re.pdf:application/pdf;arXiv.org Snapshot:/home/eigil/Zotero/storage/CB2D33YK/2207.html:text/html},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
 number = {{arXiv}:2207.08603},
 publisher = {{arXiv}},
 shorttitle = {Abstraction between Structural Causal Models},
 title = {Abstraction between Structural Causal Models: A Review of Definitions and Properties},
 url = {http://arxiv.org/abs/2207.08603},
 urldate = {2024-05-25}
}</fr:meta><fr:meta
name="doi">10.48550/arXiv.2207.08603</fr:meta><fr:meta
name="url">http://arxiv.org/abs/2207.08603</fr:meta><fr:last-changed><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date></fr:last-changed></fr:frontmatter><fr:mainmatter></fr:mainmatter><fr:backmatter><fr:contributions></fr:contributions><fr:context></fr:context><fr:related></fr:related><fr:backlinks><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>310</fr:anchor><fr:addr>efr-0002</fr:addr><fr:route>efr-0002.xml</fr:route><fr:source-path>/home/eigil/eigil-forest/trees/efr-0002.tree</fr:source-path><fr:title>Bidirectionality in graphical models</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors><fr:last-changed><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date></fr:last-changed></fr:frontmatter><fr:mainmatter><fr:p>
  There is a significant existing literature (see <fr:ref
addr="beckers_abstracting_2019"
href="beckers_abstracting_2019.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rischel_compositional_2021"
href="rischel_compositional_2021.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rubenstein_causal_2017"
href="rubenstein_causal_2017.xml"
taxon="Reference"></fr:ref>. For a survey see <fr:ref
addr="zennaro_abstraction_2022"
href="zennaro_abstraction_2022.xml"
taxon="Reference"></fr:ref>) studying transformations between structural causal models. These have generally been called something like <fr:em>abstractions,</fr:em> the typical examples being the relationship between a high-level and a low-level model of the same system. However, the precise properties that we should ask for in such a transformation have turned out to be somewhat subtle. The most obvious condition to impose is to ask, for any possible variable we could intervene on, say <fr:tex>X</fr:tex>, and any other variable (or collection of variables) <fr:tex>Y</fr:tex>, that the diagram
  
  <fr:embedded-tex
hash="56d1d417a8c926379522eaa187dcfab6"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]  \ar [d] &amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  of kernels commutes - in other words, given an intervention <fr:em>in the low-level model,</fr:em> the two possible distributions in the high-level model agree.
</fr:p><fr:p>
  The main problem with this condition is that it is simply too strict. We generally can't ask that <fr:em>every</fr:em> low-level intervention is well-modeled by the corresponding high-level intervention. Rather, each high-level intervention corresponds to some distribution of the corresponding low-level variables, and we must ask that a diagram of this form:
  
  <fr:embedded-tex
hash="1dba657b6e6d8d3bd28a2cb8942089a3"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]&amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r]  \ar [u] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  commutes. For example, if the low-level variables are the velocities of all the gas molecules in a container, and the high-level variables are thermodynamic quantities like temperature and pressure, we can't expect that <fr:em>every</fr:em> set of velocities corresponding to a given temperature will lead to a given distribution of outcomes - rather, intervening on the temperature leads to some particular distribution of possible sets of velocities, and this leads to the observed distribution of outcomes.
</fr:p><fr:p>
  The key here is that <fr:em>control information flows in the opposite direction from measurement information</fr:em>. This phenomenon repeats in many examples.
</fr:p></fr:mainmatter></fr:tree></fr:backlinks><fr:references></fr:references></fr:backmatter></fr:tree>