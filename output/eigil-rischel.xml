<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>470</fr:anchor><fr:taxon>Person</fr:taxon><fr:addr>eigil-rischel</fr:addr><fr:route>eigil-rischel.xml</fr:route><fr:title>Eigil Fjeldgren Rischel</fr:title><fr:meta
name="external">https://www.erischel.com/</fr:meta></fr:frontmatter><fr:mainmatter></fr:mainmatter><fr:backmatter><fr:contributions><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>444</fr:anchor><fr:addr>efr-000D</fr:addr><fr:route>efr-000D.xml</fr:route><fr:title>The triple category of controlled processes</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>13</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>254</fr:anchor><fr:addr>efr-000D</fr:addr><fr:route>efr-000D.xml</fr:route><fr:title>The triple category of controlled processes</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>13</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p><fr:info>Transclusion cycle</fr:info></fr:p></fr:mainmatter></fr:tree><fr:p>
  It may seem like we should simply identify a process <fr:tex>TS  \leftrightarrows  X, X  \otimes  A  \to  B</fr:tex> in the above sense with the composite <fr:tex>TS  \otimes  A  \leftrightarrows  B</fr:tex>. We will see that there is a 2-cell in a suitable higher-dimensional category relating these two processes, and this expresses an important equivalence between them, but there is a distinction between them concerning the set of possible reparametrizations - the morphisms between processes.
</fr:p><fr:p></fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>446</fr:anchor><fr:addr>efr-000C</fr:addr><fr:route>efr-000C.xml</fr:route><fr:title>Controlled Process</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>12</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Fix a monoidal dynamical systems theory <fr:tex>( \mathcal {C} , \mathcal {A} (-),T)</fr:tex>.
  Let <fr:tex>A,B  \in   \mathsf { \mathbb   Arena }</fr:tex> be two arenas. A <fr:em>controlled process</fr:em> <fr:tex>A  \nrightarrow  B</fr:tex> consists of a tuple
  <fr:tex
display="block">(X  \in   \mathsf { \mathbb   Arena } , C  \in   \mathsf { \mathbb   System } _X, p: C  \otimes  A  \leftrightarrows  Y)</fr:tex></fr:p><fr:p>
  In other words: a third arena <fr:tex>X</fr:tex>, a system on <fr:tex>X</fr:tex> (that is, an object <fr:tex>S  \in   \mathcal {C}</fr:tex> and a lens <fr:tex>c: TS  \leftrightarrows  X</fr:tex>,) and a parameterized lens <fr:tex>C  \otimes  A  \to  Y</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>448</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-000B</fr:addr><fr:route>efr-000B.xml</fr:route><fr:title>Controlled Lens</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>6</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Let <fr:tex>( \mathcal {C} , \mathcal {A} ,T)</fr:tex> be a <fr:link
href="efr-000A.xml"
type="local"
addr="efr-000A">monoidal theory of dynamical systems</fr:link>. Then the <fr:em>double category of controlled lenses</fr:em> is defined as follows:
  <fr:ol><fr:li>The objects are the arenas, objects of <fr:tex>\int   \mathcal {A}</fr:tex></fr:li>
    <fr:li>The vertical category is simply the category of charts</fr:li>
    <fr:li>A horizontal morphism is a <fr:em>controlled lens,</fr:em> a tuple <fr:tex>S  \in   \mathcal {C} , TS  \otimes  A  \to  B</fr:tex></fr:li>
    <fr:li>Horizontal composition is by tensoring</fr:li>
    <fr:li>A 2-cell is a map <fr:tex>S  \to  S'</fr:tex> so that the induced diagram in the double category of lenses and charts commutes.</fr:li></fr:ol></fr:p><fr:p>
  We could extend this to a triple category, where the third type of morphism is a bare lens, and a commutative square of controlled lenses and bare lenses must satisfy a different commutativity equation.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>450</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-000A</fr:addr><fr:route>efr-000A.xml</fr:route><fr:title>Theory of Dynamical Systems</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>6</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  A <fr:em>theory of dynamical systems</fr:em> is an indexed category <fr:tex>\mathcal {A} :  \mathcal {C} ^ \mathrm {op}   \to   \mathsf { Cat }</fr:tex> equipped with a section of its Grothendieck construction <fr:tex>T:  \mathcal {C}   \to   \int   \mathcal {A}</fr:tex>.
</fr:p><fr:p>
  It is called <fr:em>monoidal</fr:em> if <fr:tex>\int   \mathcal {A}   \to   \mathcal {C}</fr:tex> is equipped with the structure of a monoidal fibration (equivalently, if <fr:tex>\mathcal {C}</fr:tex> is monoidal an <fr:tex>\mathcal {A}</fr:tex> is lax monoidal for the Cartesian structure on <fr:tex>\mathsf { Cat }</fr:tex>), and <fr:tex>T</fr:tex> is a strong monoidal functor.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>452</fr:anchor><fr:addr>efr-0008</fr:addr><fr:route>efr-0008.xml</fr:route><fr:title>Acknowledgements</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>5</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Advisors
  Neil Ghani
  Radu Mardare
</fr:p><fr:p>
  MSP group
  Alasdair Lambert
  Andre Videla
  Guillaume Allais
  Ezra Schoen
  Malin Altenmuller

</fr:p><fr:p>
  Conversations
  Matteo Capucci, Jules Hedges, Bruno Gavranovic, David Spivak, Brandon Shapiro, Toby Smithe, Riu Nakamura, Dylan Braithwaite, Davidad, Evan Patterson, Owen Lynch, Jade Master
</fr:p><fr:p>
  Tobias Fritz, Paolo Perrone, Tomas Gonda. 
</fr:p><fr:p>
  Pawel Sobocinski, Chad Nester, Mario Roman, Elena di Lavore, Diana Kessler
</fr:p><fr:p>
  Benjamin Bumpus
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>454</fr:anchor><fr:addr>efr-0009</fr:addr><fr:route>efr-0009.xml</fr:route><fr:title>Composition with graded predicates</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>5</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Suppose <fr:tex>T: X  \to   \Delta (Y)</fr:tex> is a stochastic map, and suppose <fr:tex>\phi ^ \epsilon</fr:tex> is a graded predicate on <fr:tex>Y</fr:tex> (in particular, <fr:tex>\phi ^ \epsilon (y)  \Rightarrow   \phi ^{ \epsilon '}(y)</fr:tex> if <fr:tex>\epsilon  &lt;  \epsilon '</fr:tex>).
</fr:p><fr:p>
  Then we can define <fr:tex>T^{-1}( \phi )^ \epsilon</fr:tex>, a graded predicate on <fr:tex>X</fr:tex>, by <fr:tex>T^{-1}( \phi )^ \epsilon (x)</fr:tex> if there exists <fr:tex>\epsilon _1 +  \epsilon _2 =  \epsilon</fr:tex> with <fr:tex>P( \phi ^{ \epsilon _1}(Tx)) &gt; 1- \epsilon _2</fr:tex></fr:p><fr:p>
  Every graded predicate <fr:tex>\phi</fr:tex> on <fr:tex>X</fr:tex> is the pullback of the predicate <fr:tex>x =  \top</fr:tex> on <fr:tex>\{ \bot , \top \}</fr:tex> along a unique stochastic map <fr:tex>[ \phi ]: X  \to   \{ \bot , \top \}</fr:tex> (which carries <fr:tex>x</fr:tex> to the distribution which is <fr:tex>\bot</fr:tex> with probability <fr:tex>\inf _{ \phi ^ \epsilon (x)}  \epsilon</fr:tex>). Thus a graded predicate is essentially a stochastic version of an ordinary predicate (which is a <fr:em>deterministic</fr:em> map to <fr:tex>\{ \bot , \top \}</fr:tex>). Under this equivalence, the operation <fr:tex>T^{-1}</fr:tex> is simply precomposition with <fr:tex>T</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>456</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-0005</fr:addr><fr:route>efr-0005.xml</fr:route><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  In a dynamical systems theory, a <fr:em>Mealy machine</fr:em> with state space <fr:tex>S</fr:tex> and interface <fr:tex>A</fr:tex> consists of a costate <fr:tex>TS  \otimes  A  \to  I</fr:tex>. The category of Mealy machines with interface <fr:tex>A</fr:tex> is the comma category of the functor <fr:tex>T(-)  \otimes  A</fr:tex> over <fr:tex>I</fr:tex> - that is, a morphism of Mealy machines is <fr:tex>S  \to  S'</fr:tex> so that the obvious triangle commutes.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>458</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-0006</fr:addr><fr:route>efr-0006.xml</fr:route><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  In a dynamical systems theory, a <fr:em>Moore machine</fr:em> with state space <fr:tex>S</fr:tex> and interface <fr:tex>A</fr:tex> is a morphism <fr:tex>TS  \to  A</fr:tex>. The category of Moore machines with interface <fr:tex>A</fr:tex> is the slice category of the functor <fr:tex>T</fr:tex> over <fr:tex>A</fr:tex> - that is, a morphism of Moore machines is a morphism <fr:tex>S  \to  S'</fr:tex> so that the obvious triangle commutes.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>460</fr:anchor><fr:taxon>Remark</fr:taxon><fr:addr>efr-0007</fr:addr><fr:route>efr-0007.xml</fr:route><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  A Moore machine in the sense of <fr:ref
addr="efr-0006"
href="efr-0006.xml"
taxon="Definition"></fr:ref> is what Myers calls a (open) dynamical system, and they are the central object of study in <fr:link
href="myers-cst.xml"
type="local"
addr="myers-cst">Categorical Systems Theory</fr:link>. Arguably, both Moore machines and Mealy machines (<fr:ref
addr="efr-0005"
href="efr-0005.xml"
taxon="Definition"></fr:ref>) deserve the name of "open dynamical system" - the difference is is how they interact with the external world.
</fr:p><fr:p>
  Observe in particular that, if <fr:tex>A=I</fr:tex>, the categories of Mealy and Moore machines agree, both being equal to the slice of <fr:tex>T</fr:tex> over the unit <fr:tex>I</fr:tex>. In other words, the two notions of <fr:em>closed</fr:em> dynamical system coincide.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>462</fr:anchor><fr:addr>efr-0004</fr:addr><fr:route>efr-0004.xml</fr:route><fr:title>Bidirectionality for control</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Consider a discrete-time, continuous-space, controlled, nonlinear dynamical system with noise.
  By this, I mean some transition function <fr:tex>F(x,u):  \mathbb {R} ^n  \times   \mathbb {R} ^p  \to   \mathbb {R} ^n,</fr:tex> along with a given "noise distribution" <fr:tex>\mu</fr:tex> on <fr:tex>\mathbb {R} ^n</fr:tex>.
  The intended meaning is that <fr:tex>x_{n+1} = F(x_n,u_n) + v_n</fr:tex>, where <fr:tex>u_n  \in   \mathbb {R} ^p</fr:tex> is a variable which can be controlled (depending on <fr:tex>x_1,  \dots  x_n</fr:tex>,) and <fr:tex>(v_n)_{n=0, \dots }</fr:tex> is a sequence of iid random variables distributed according to <fr:tex>\mu</fr:tex> (for simplicity, we assume everything is time-invariant). Without any assumptions of linearity or the like on <fr:tex>F</fr:tex>, it is hard to apply traditional control methods. Therefore we'd like to partition <fr:tex>\mathbb {R} ^n</fr:tex> into a discrete set of components, and apply reinforcement learning algorithms to the resulting dynamics (or just straightforward dynamical programming, depending on the situation).
</fr:p><fr:p>
  Suppose we have such a partition <fr:tex>p:  \mathbb {R} ^n  \to  I</fr:tex>, with <fr:tex>I</fr:tex> some discrete index set. We want to build some sort of controlled dynamical system on <fr:tex>I</fr:tex> (really a Markov Decision Problem). A priori, however, it seems the probability of being able to transition from <fr:tex>i</fr:tex> to <fr:tex>j</fr:tex> is highly dependent on where in <fr:tex>p^{-1}(i)</fr:tex> we are.
</fr:p><fr:p>
  The trick to building an MDP is to choose <fr:tex>u(x,i)</fr:tex>, where <fr:tex>x</fr:tex> is our current state and <fr:tex>i</fr:tex> is the target region, in such a way that <fr:tex>x^i := F(x,u(x,i))</fr:tex> does not depend on <fr:tex>x</fr:tex> - then the distribution on the next state is just the distribution of <fr:tex>p(x^i + v_n)</fr:tex>, which can be determined ahead of time for each <fr:tex>i</fr:tex>. <fr:tex>i  \mapsto  x^i</fr:tex> is a section of <fr:tex>p</fr:tex> - this bidirectionality is completely analogous to what we saw for abstractions between graphical models. 
</fr:p><fr:p>
  The datum <fr:tex>u(-,=):  \mathbb {R} ^n  \times  I  \to   \mathbb {R} ^p</fr:tex> is the backwards part of a <fr:em>lens</fr:em> <fr:tex>\binom { \mathbb {R} ^p}{ \mathbb {R} ^n}  \to   \binom {I}{I}</fr:tex>. Actually, this raises a subtlety we swept under the rug above - it may not be possible to find <fr:tex>u(x,i)</fr:tex> satisfying <fr:tex>F(x,u(x,i)) = x_i</fr:tex> for all pairs <fr:tex>x,i</fr:tex>. Hence we need to restrict ourselves to those where it is possible - and because we're trying to abstract away <fr:tex>x</fr:tex>, we need to consider those <fr:tex>i</fr:tex> so that it's possible for all <fr:tex>x</fr:tex> in our current component. This will bring us to consider <fr:em>dependent</fr:em> lenses.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>464</fr:anchor><fr:addr>efr-0002</fr:addr><fr:route>efr-0002.xml</fr:route><fr:title>Bidirectionality in graphical models</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>272</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-0003</fr:addr><fr:route>efr-0003.xml</fr:route><fr:title>Structural Causal Model</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Let <fr:tex>G</fr:tex> be a (finite) directed acyclic graph (DAG). Then a structural causal model (SCM) on <fr:tex>G</fr:tex> consists of
  <fr:ul><fr:li>For each vertex <fr:tex>v  \in  V(G)</fr:tex>, measurable spaces <fr:tex>\mathcal {X} _v</fr:tex>, {<fr:tex>\mathcal {E}</fr:tex>_v}</fr:li>
    <fr:li>A family of independent random variables <fr:tex>E_v  \in   \mathcal {E} _v</fr:tex> - these are called the <fr:em>exogenous variables</fr:em></fr:li>
    <fr:li>For each <fr:tex>v</fr:tex>, a measurable function <fr:tex>\phi _v:  \mathcal {E} _v   \times   \prod _{v'  \to  v}  \mathcal {X} _{v'}  \to   \mathcal {X} _v</fr:tex> (note that if <fr:tex>v</fr:tex> has no parents, the product is just a singleton)</fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
  There is a significant existing literature (see <fr:ref
addr="beckers_abstracting_2019"
href="beckers_abstracting_2019.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rischel_compositional_2021"
href="rischel_compositional_2021.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rubenstein_causal_2017"
href="rubenstein_causal_2017.xml"
taxon="Reference"></fr:ref>. For a survey see <fr:ref
addr="zennaro_abstraction_2022"
href="zennaro_abstraction_2022.xml"
taxon="Reference"></fr:ref>) studying transformations between structural causal models. These have generally been called something like <fr:em>abstractions,</fr:em> the typical examples being the relationship between a high-level and a low-level model of the same system. However, the precise properties that we should ask for in such a transformation have turned out to be somewhat subtle. The most obvious condition to impose is to ask, for any possible variable we could intervene on, say <fr:tex>X</fr:tex>, and any other variable (or collection of variables) <fr:tex>Y</fr:tex>, that the diagram
  
  <fr:embedded-tex
hash="56d1d417a8c926379522eaa187dcfab6"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]  \ar [d] &amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  of kernels commutes - in other words, given an intervention <fr:em>in the low-level model,</fr:em> the two possible distributions in the high-level model agree.
</fr:p><fr:p>
  The main problem with this condition is that it is simply too strict. We generally can't ask that <fr:em>every</fr:em> low-level intervention is well-modeled by the corresponding high-level intervention. Rather, each high-level intervention corresponds to some distribution of the corresponding low-level variables, and we must ask that a diagram of this form:
  
  <fr:embedded-tex
hash="1dba657b6e6d8d3bd28a2cb8942089a3"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]&amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r]  \ar [u] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  commutes. For example, if the low-level variables are the velocities of all the gas molecules in a container, and the high-level variables are thermodynamic quantities like temperature and pressure, we can't expect that <fr:em>every</fr:em> set of velocities corresponding to a given temperature will lead to a given distribution of outcomes - rather, intervening on the temperature leads to some particular distribution of possible sets of velocities, and this leads to the observed distribution of outcomes.
</fr:p><fr:p>
  The key here is that <fr:em>control information flows in the opposite direction from measurement information</fr:em>. This phenomenon repeats in many examples.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>466</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-0003</fr:addr><fr:route>efr-0003.xml</fr:route><fr:title>Structural Causal Model</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Let <fr:tex>G</fr:tex> be a (finite) directed acyclic graph (DAG). Then a structural causal model (SCM) on <fr:tex>G</fr:tex> consists of
  <fr:ul><fr:li>For each vertex <fr:tex>v  \in  V(G)</fr:tex>, measurable spaces <fr:tex>\mathcal {X} _v</fr:tex>, {<fr:tex>\mathcal {E}</fr:tex>_v}</fr:li>
    <fr:li>A family of independent random variables <fr:tex>E_v  \in   \mathcal {E} _v</fr:tex> - these are called the <fr:em>exogenous variables</fr:em></fr:li>
    <fr:li>For each <fr:tex>v</fr:tex>, a measurable function <fr:tex>\phi _v:  \mathcal {E} _v   \times   \prod _{v'  \to  v}  \mathcal {X} _{v'}  \to   \mathcal {X} _v</fr:tex> (note that if <fr:tex>v</fr:tex> has no parents, the product is just a singleton)</fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="true"><fr:frontmatter><fr:anchor>468</fr:anchor><fr:addr>efr-0001</fr:addr><fr:route>index.xml</fr:route><fr:title>The Heuristic Control of Complex Systems</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>274</fr:anchor><fr:addr>efr-0002</fr:addr><fr:route>efr-0002.xml</fr:route><fr:title>Bidirectionality in graphical models</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>272</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>efr-0003</fr:addr><fr:route>efr-0003.xml</fr:route><fr:title>Structural Causal Model</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Let <fr:tex>G</fr:tex> be a (finite) directed acyclic graph (DAG). Then a structural causal model (SCM) on <fr:tex>G</fr:tex> consists of
  <fr:ul><fr:li>For each vertex <fr:tex>v  \in  V(G)</fr:tex>, measurable spaces <fr:tex>\mathcal {X} _v</fr:tex>, {<fr:tex>\mathcal {E}</fr:tex>_v}</fr:li>
    <fr:li>A family of independent random variables <fr:tex>E_v  \in   \mathcal {E} _v</fr:tex> - these are called the <fr:em>exogenous variables</fr:em></fr:li>
    <fr:li>For each <fr:tex>v</fr:tex>, a measurable function <fr:tex>\phi _v:  \mathcal {E} _v   \times   \prod _{v'  \to  v}  \mathcal {X} _{v'}  \to   \mathcal {X} _v</fr:tex> (note that if <fr:tex>v</fr:tex> has no parents, the product is just a singleton)</fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
  There is a significant existing literature (see <fr:ref
addr="beckers_abstracting_2019"
href="beckers_abstracting_2019.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rischel_compositional_2021"
href="rischel_compositional_2021.xml"
taxon="Reference"></fr:ref>, <fr:ref
addr="rubenstein_causal_2017"
href="rubenstein_causal_2017.xml"
taxon="Reference"></fr:ref>. For a survey see <fr:ref
addr="zennaro_abstraction_2022"
href="zennaro_abstraction_2022.xml"
taxon="Reference"></fr:ref>) studying transformations between structural causal models. These have generally been called something like <fr:em>abstractions,</fr:em> the typical examples being the relationship between a high-level and a low-level model of the same system. However, the precise properties that we should ask for in such a transformation have turned out to be somewhat subtle. The most obvious condition to impose is to ask, for any possible variable we could intervene on, say <fr:tex>X</fr:tex>, and any other variable (or collection of variables) <fr:tex>Y</fr:tex>, that the diagram
  
  <fr:embedded-tex
hash="56d1d417a8c926379522eaa187dcfab6"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]  \ar [d] &amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  of kernels commutes - in other words, given an intervention <fr:em>in the low-level model,</fr:em> the two possible distributions in the high-level model agree.
</fr:p><fr:p>
  The main problem with this condition is that it is simply too strict. We generally can't ask that <fr:em>every</fr:em> low-level intervention is well-modeled by the corresponding high-level intervention. Rather, each high-level intervention corresponds to some distribution of the corresponding low-level variables, and we must ask that a diagram of this form:
  
  <fr:embedded-tex
hash="1dba657b6e6d8d3bd28a2cb8942089a3"><fr:embedded-tex-preamble>\usepackage {quiver, amsopn, amssymb, mathrsfs}</fr:embedded-tex-preamble><fr:embedded-tex-body>
     \begin {tikzcd}
     \mathcal {A}_X  \ar [r]&amp;  \mathcal {A}_Y  \ar [d] \\ 
     \mathcal {A}_{f(X)}  \ar [r]  \ar [u] &amp;  \mathcal {A}_{f(Y)}
     \end {tikzcd}
  </fr:embedded-tex-body></fr:embedded-tex>

  commutes. For example, if the low-level variables are the velocities of all the gas molecules in a container, and the high-level variables are thermodynamic quantities like temperature and pressure, we can't expect that <fr:em>every</fr:em> set of velocities corresponding to a given temperature will lead to a given distribution of outcomes - rather, intervening on the temperature leads to some particular distribution of possible sets of velocities, and this leads to the observed distribution of outcomes.
</fr:p><fr:p>
  The key here is that <fr:em>control information flows in the opposite direction from measurement information</fr:em>. This phenomenon repeats in many examples.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>276</fr:anchor><fr:addr>efr-0004</fr:addr><fr:route>efr-0004.xml</fr:route><fr:title>Bidirectionality for control</fr:title><fr:date><fr:year>2024</fr:year><fr:month>5</fr:month><fr:day>25</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Consider a discrete-time, continuous-space, controlled, nonlinear dynamical system with noise.
  By this, I mean some transition function <fr:tex>F(x,u):  \mathbb {R} ^n  \times   \mathbb {R} ^p  \to   \mathbb {R} ^n,</fr:tex> along with a given "noise distribution" <fr:tex>\mu</fr:tex> on <fr:tex>\mathbb {R} ^n</fr:tex>.
  The intended meaning is that <fr:tex>x_{n+1} = F(x_n,u_n) + v_n</fr:tex>, where <fr:tex>u_n  \in   \mathbb {R} ^p</fr:tex> is a variable which can be controlled (depending on <fr:tex>x_1,  \dots  x_n</fr:tex>,) and <fr:tex>(v_n)_{n=0, \dots }</fr:tex> is a sequence of iid random variables distributed according to <fr:tex>\mu</fr:tex> (for simplicity, we assume everything is time-invariant). Without any assumptions of linearity or the like on <fr:tex>F</fr:tex>, it is hard to apply traditional control methods. Therefore we'd like to partition <fr:tex>\mathbb {R} ^n</fr:tex> into a discrete set of components, and apply reinforcement learning algorithms to the resulting dynamics (or just straightforward dynamical programming, depending on the situation).
</fr:p><fr:p>
  Suppose we have such a partition <fr:tex>p:  \mathbb {R} ^n  \to  I</fr:tex>, with <fr:tex>I</fr:tex> some discrete index set. We want to build some sort of controlled dynamical system on <fr:tex>I</fr:tex> (really a Markov Decision Problem). A priori, however, it seems the probability of being able to transition from <fr:tex>i</fr:tex> to <fr:tex>j</fr:tex> is highly dependent on where in <fr:tex>p^{-1}(i)</fr:tex> we are.
</fr:p><fr:p>
  The trick to building an MDP is to choose <fr:tex>u(x,i)</fr:tex>, where <fr:tex>x</fr:tex> is our current state and <fr:tex>i</fr:tex> is the target region, in such a way that <fr:tex>x^i := F(x,u(x,i))</fr:tex> does not depend on <fr:tex>x</fr:tex> - then the distribution on the next state is just the distribution of <fr:tex>p(x^i + v_n)</fr:tex>, which can be determined ahead of time for each <fr:tex>i</fr:tex>. <fr:tex>i  \mapsto  x^i</fr:tex> is a section of <fr:tex>p</fr:tex> - this bidirectionality is completely analogous to what we saw for abstractions between graphical models. 
</fr:p><fr:p>
  The datum <fr:tex>u(-,=):  \mathbb {R} ^n  \times  I  \to   \mathbb {R} ^p</fr:tex> is the backwards part of a <fr:em>lens</fr:em> <fr:tex>\binom { \mathbb {R} ^p}{ \mathbb {R} ^n}  \to   \binom {I}{I}</fr:tex>. Actually, this raises a subtlety we swept under the rug above - it may not be possible to find <fr:tex>u(x,i)</fr:tex> satisfying <fr:tex>F(x,u(x,i)) = x_i</fr:tex> for all pairs <fr:tex>x,i</fr:tex>. Hence we need to restrict ourselves to those where it is possible - and because we're trying to abstract away <fr:tex>x</fr:tex>, we need to consider those <fr:tex>i</fr:tex> so that it's possible for all <fr:tex>x</fr:tex> in our current component. This will bring us to consider <fr:em>dependent</fr:em> lenses.
</fr:p></fr:mainmatter></fr:tree><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>278</fr:anchor><fr:addr>efr-0009</fr:addr><fr:route>efr-0009.xml</fr:route><fr:title>Composition with graded predicates</fr:title><fr:date><fr:year>2024</fr:year><fr:month>6</fr:month><fr:day>5</fr:day></fr:date><fr:authors><fr:author><fr:link
href="eigil-rischel.xml"
type="local"
addr="eigil-rischel">Eigil Fjeldgren Rischel</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>
  Suppose <fr:tex>T: X  \to   \Delta (Y)</fr:tex> is a stochastic map, and suppose <fr:tex>\phi ^ \epsilon</fr:tex> is a graded predicate on <fr:tex>Y</fr:tex> (in particular, <fr:tex>\phi ^ \epsilon (y)  \Rightarrow   \phi ^{ \epsilon '}(y)</fr:tex> if <fr:tex>\epsilon  &lt;  \epsilon '</fr:tex>).
</fr:p><fr:p>
  Then we can define <fr:tex>T^{-1}( \phi )^ \epsilon</fr:tex>, a graded predicate on <fr:tex>X</fr:tex>, by <fr:tex>T^{-1}( \phi )^ \epsilon (x)</fr:tex> if there exists <fr:tex>\epsilon _1 +  \epsilon _2 =  \epsilon</fr:tex> with <fr:tex>P( \phi ^{ \epsilon _1}(Tx)) &gt; 1- \epsilon _2</fr:tex></fr:p><fr:p>
  Every graded predicate <fr:tex>\phi</fr:tex> on <fr:tex>X</fr:tex> is the pullback of the predicate <fr:tex>x =  \top</fr:tex> on <fr:tex>\{ \bot , \top \}</fr:tex> along a unique stochastic map <fr:tex>[ \phi ]: X  \to   \{ \bot , \top \}</fr:tex> (which carries <fr:tex>x</fr:tex> to the distribution which is <fr:tex>\bot</fr:tex> with probability <fr:tex>\inf _{ \phi ^ \epsilon (x)}  \epsilon</fr:tex>). Thus a graded predicate is essentially a stochastic version of an ordinary predicate (which is a <fr:em>deterministic</fr:em> map to <fr:tex>\{ \bot , \top \}</fr:tex>). Under this equivalence, the operation <fr:tex>T^{-1}</fr:tex> is simply precomposition with <fr:tex>T</fr:tex>.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:contributions><fr:context></fr:context><fr:related></fr:related><fr:backlinks></fr:backlinks><fr:references></fr:references></fr:backmatter></fr:tree>