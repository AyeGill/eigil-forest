[{"DOI": "10.1613/jair.1.14253", "ISSN": "1076-9757", "URL": "https://jair.org/index.php/jair/article/view/14253", "abstract": "Controllers for dynamical systems that operate in safety-critical settings must account for stochastic disturbances. Such disturbances are often modeled as process noise in a dynamical system, and common assumptions are that the underlying distributions are known and/or Gaussian. In practice, however, these assumptions may be unrealistic and can lead to poor approximations of the true noise distribution. We present a novel controller synthesis method that does not rely on any explicit representation of the noise distributions. In particular, we address the problem of computing a controller that provides probabilistic guarantees on safely reaching a target, while also avoiding unsafe regions of the state space. First, we abstract the continuous control system into a finite-state model that captures noise by probabilistic transitions between discrete states. As a key contribution, we adapt tools from the scenario approach to compute probably approximately correct (PAC) bounds on these transition probabilities, based on a finite number of samples of the noise. We capture these bounds in the transition probability intervals of a so-called interval Markov decision process (iMDP). This iMDP is, with a user-specified confidence probability, robust against uncertainty in the transition probabilities, and the tightness of the probability intervals can be controlled through the number of samples. We use state-of-the-art verification techniques to provide guarantees on the iMDP and compute a controller for which these guarantees carry over to the original control system. In addition, we develop a tailored computational scheme that reduces the complexity of the synthesis of these guarantees on the iMDP. Benchmarks on realistic control systems show the practical applicability of our method, even when the iMDP has hundreds of millions of transitions.", "accessed": {"date-parts": [[2024, 3, 6]]}, "author": [{"family": "Badings", "given": "Thom"}, {"family": "Romao", "given": "Licio"}, {"family": "Abate", "given": "Alessandro"}, {"family": "Parker", "given": "David"}, {"family": "Poonawala", "given": "Hasan A."}, {"family": "Stoelinga", "given": "Marielle"}, {"family": "Jansen", "given": "Nils"}], "container-title": "Journal of Artificial Intelligence Research", "id": "badings_robust_2023", "issued": {"date-parts": [[2023, 1, 21]]}, "keyword": "markov decision processes, probabilistic reasoning, uncertainty", "language": "en-US", "page": "341-391", "title": "Robust control for dynamical systems with non-gaussian noise via formal abstractions", "type": "article-journal", "volume": "76", "original_bibtex": "@article{badings_robust_2023,\n abstract = {Controllers for dynamical systems that operate in safety-critical settings must account for stochastic disturbances. Such disturbances are often modeled as process noise in a dynamical system, and common assumptions are that the underlying distributions are known and/or Gaussian. In practice, however, these assumptions may be unrealistic and can lead to poor approximations of the true noise distribution. We present a novel controller synthesis method that does not rely on any explicit representation of the noise distributions. In particular, we address the problem of computing a controller that provides probabilistic guarantees on safely reaching a target, while also avoiding unsafe regions of the state space. First, we abstract the continuous control system into a finite-state model that captures noise by probabilistic transitions between discrete states. As a key contribution, we adapt tools from the scenario approach to compute probably approximately correct ({PAC}) bounds on these transition probabilities, based on a finite number of samples of the noise. We capture these bounds in the transition probability intervals of a so-called interval Markov decision process ({iMDP}). This {iMDP} is, with a user-specified confidence probability, robust against uncertainty in the transition probabilities, and the tightness of the probability intervals can be controlled through the number of samples. We use state-of-the-art verification techniques to provide guarantees on the {iMDP} and compute a controller for which these guarantees carry over to the original control system. In addition, we develop a tailored computational scheme that reduces the complexity of the synthesis of these guarantees on the {iMDP}. Benchmarks on realistic control systems show the practical applicability of our method, even when the {iMDP} has hundreds of millions of transitions.},\n author = {Badings, Thom and Romao, Licio and Abate, Alessandro and Parker, David and Poonawala, Hasan A. and Stoelinga, Marielle and Jansen, Nils},\n date = {2023-01-21},\n doi = {10.1613/jair.1.14253},\n file = {Full Text PDF:/home/eigil/Zotero/storage/4KYNP6D2/Badings et al. - 2023 - Robust Control for Dynamical Systems with Non-Gaus.pdf:application/pdf},\n issn = {1076-9757},\n journaltitle = {Journal of Artificial Intelligence Research},\n keywords = {markov decision processes, probabilistic reasoning, uncertainty},\n langid = {english},\n pages = {341--391},\n rights = {Copyright (c) 2023 Journal of Artificial Intelligence Research},\n title = {Robust Control for Dynamical Systems with Non-Gaussian Noise via Formal Abstractions},\n url = {https://jair.org/index.php/jair/article/view/14253},\n urldate = {2024-03-06},\n volume = {76}\n}\n"}]