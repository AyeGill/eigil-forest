\date{2024-07-15}
\author{eigil-rischel}
\import{macros}
\title{The opposite of #{\FinStoch}}
\p{
  Recall that (perhaps by definition, perhaps as a trivial theorem, depending on our choice of definition), there is a faithful functor #{\FinStoch \to \Vect} carrying a set #{X} to the vector space #{\RR\braket{X}} freely generated by #{X}, and a stochastic map #{f: X \to Y} to the map which takes the basis vector #{x \in X} to the linear combination #{\sum_{y \in Y} y f(y|x)}. The essential image of this functor is, of course, the finite-dimensional vector spaces. The morphisms in the image are the \em{stochastic matrices}, which can be characterized as those that are \em{positive} (they carry vectors with positive coordinates to other such vectors) and preserve the constant #{1} vector (note that neither of these properties are invariant under isomorphism of finite-dimensional vector space).
}
\p{
  One way to think about this is that it proves #{\FinStoch} is equivalent to the category of \em{finite-dimensional, ordered, pointed} vector spaces, where we assume that the chosen point must be positive in the order. (To see the inclusion is essentially surjective, note that given a vector space pointed by #{(a_1, \dots a_n)}, all those coordinates positive, it receives an isomorphism from the same spaces pointed by #{(1, \dots 1)} given by the diagonal matrix with entries #{a_1, \dots a_n}).
}
\p{
  Now, let #{\fdVect^\leq} denote the category of finite-dimensional ordered vector spaces. Then equipping a space #{V} with a positive point is exactly choosing an order-preserving linear map #{\RR \to V}, so we have proven #{\FinStoch \simeq \fdVect^\leq_{ \RR /}}. Now we can compute
  ##{\FinStoch^\op \simeq (\fdVect^\leq_{ \ RR/})^\op \cong (\fdVect^\leq)^\op_{ / \RR} \cong \fdVect^\leq_{ / \RR},}
  where the last isomorphism is via transposition (note that transposing a positive matrix yields a positive matrix).
}
\p{
  This isomorphism merely describes the fact that stochastic maps #{\phi: X \to Y} can also be described as linear maps #{f: \RR\braket{Y} \to \RR\braket{X}} so that #{\sum_x f((a_y))_x = \sum_y a_y}. This map interprets a vector as a function on #{Y}, and carries it to the function on #{X} which finds the expected value if #{y \in Y} is distributed as #{\phi(x)}. The normalization condition merely says a constant function always has that constant as its expectation.
}
\p{
  The self-duality of #{\fdVect} does not generalize to infinite-dimensional vector spaces, so once we move beyond finite state spaces, this story will get somewhat more complicated. However, the basic idea that, to carry the tools of coalgebraic modal logic into the stochastic case, the sort of "predicate" we should consider is actually a \em{function} on the state space, will remain the central idea.
}
\p{
  (Indeed, to consider the right notion of stochastic function between, for example, smooth manifolds, we will in any case want to use the tools of functional analysis to think of these in terms of transformation on integration operators, which is essentially this idea).
}
\p{
  Another way to justify this idea is to note that #{\Omega = \{\bot,\top\}} is the subobject classifier for #{\FinSet \subseteq \FinStoch}. Hence if we want our notion of predicate to transform under stochastic maps, and include the logical predicates in the usual sense, we have to at least consider the stochastic maps #{X \to \Omega}, which of course amount to functions #{X \to [0,1]} in this case. But a positive linear map on functions is determined by what it does to functions like this, so whether we work only with these or all functions #{X \to \RR} is more or less a matter of taste.
}
\p{
  Instead of having a logic consisting of the operations of Boolean algebra, augmented with extra operations described by #{T^\op B \to B}, we have the operations of a vector space, augmented by some extra modal operations. The Markov structure of #{\FinStoch,} or whichever category we work in, will give the vector space of functions an #{\RR}-algebra structure, but we should note that some equations fail to hold in general (dual to the fact that not all morphisms in the Markov category are homomorphisms for the comonoid structure). The Hennesy-Milner property is essentially the same in this situation, saying that our set of modally-expressable functions should separate points in the terminal coalgebra. Since we will have multiplication and linear combinations of functions, this entails under some mild topological conditions that it's \em{dense} in the set of functions on the terminal coalgebra.
}