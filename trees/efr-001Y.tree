\date{2024-06-28}
\author{eigil-rischel}
\import{macros}
\p{
  When moving from deterministic, ordinary differential equations, to stochastic differential equations---or, from another point of approach, moving from discrete-time stochastic systems to continuous-time stochastic systems---we are forced to confront the problem that typical stochastic differential equations do not have differentiable solutions.
}
\p{
  A few questions immediately pose themselves when confronted with this statement:
  \ol{
    \li{Since a solution of a stochastic differential equation is not merely a function but some sort of distribution of functions, what do you mean by them not being differentiable?}
    \li{Whatever the solutions are, how can they solve a differential equation if they aren't't differentiable?}
  }
}
\p{
  It will be instructive to consider Brownian motion. For each #{t \in \RR}, let #{E_t} be an independent standard Gaussian. There are some issues with defining the integral #{X_r = \int_0^r E_t dt,} since #{t \mapsto E_t} can't be guaranteed to be even measurable, but these can be sidestepped without too many problems. Then #{X_r} is Brownian motion, but with probability #{1} it is nowhere differentiable. The integral equation above describes the sense in which #{X} solves a stochastic differential equation saying it's derivative at each point is standard Gaussian distributed.
}
\p{
  Of course, since not all systems are integrable (this is not even true in the deterministic case,) there is not gonna be an integral operator lying around that we can use to define the solutions of our differential equations. Hence we must use a different solution concept.
}
\p{
  Recall that, if #{f,g: \RR \to \RR} are differentiable functions, 
  #{\int_a^b f(x)g'(x)dx = f(a)g(a)---f(b)g(b)---\int_a^b f'(x)g(x)dx,}
  (integration by parts). Now if we choose #{f} to be zero except on a bounded interval, and let the endpoints to infinity, we get #{\int_\RR f(x)g'(x) dx =---\int_\RR f'(x)g(x)dx}. The trick here is that the right-hand side is defined even if #{g} is not differentiable, and so it gives us a way of talking about "the derivative of #{g}", at least for some purposes, even when it doesn't exist.
}
\p{
  Since two functions have the same integral after multiplication by every differentiable #{f}, if and only if they're equal almost everywhere, this is fairly robust---if #{g} is #{C^1} and satisfies some differential equation "weakly", it follows it must satisfy it on the nose as well, for example.
}


\transclude{efr-001Z}
\p{
  Let #{\phi: C_c(Y) \to C_c(X)} be a positive linear map. Then dualizing gives a linear map #{\phi^*: C_c(X)^* \to C_c(Y)^*}. If we assume the initial map preserves the constant #{1} function,, this will preserve probability measures, making it a sort of infinity-dimensional stochastic matrix.
}
\p{
  In particular, we get a composite map #{X \to C_c(X)^* \to C_c(Y)^*,} where the first map just includes the dirac measures (or, alternatively, takes #{x} to the "evaluate at #{x}" functional).
}
\p{
  If we further assume #{\phi} is continuous for the uniform convergence topology, #{\phi^*} will be continuous for the pointwise convergence topology. Since every probability measure is a limit of linear combinations of dirac measures in this topology, that means #{\phi^*} will be controlled by the above map, so we really have an injective correspondence between linear, continuous and unit-preserving maps #{C_c(Y) \to C_c(X)} and some subset of the Markov kernels #{X \to Y}.
}
\p{
  If we stare at this sequence of composites a bit, we realize that the linear operation corresponding to a kernel #{pX \to Y} carries a function #{f: Y \to \RR} to the expected value function #{x \mapsto E_{y \sim p(x)} f(y)}. Not all Markov kernels will have the property that this preserves continuity of #{f} (all measurable functions are Markov kernels, even)---but we would probably want to impose some notion of continuity on our kernels in any case.
}
\p{
  Instead of thinking about the classes of Markov kernels with this continuity-of-expectation property, we can simply use the space of continuous, unit-preserving linear maps #{C_c(Y) \to C_c(X)} as our class of stochastic maps #{X \to Y.}
}